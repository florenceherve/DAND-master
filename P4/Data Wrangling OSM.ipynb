{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Wrangling - Perth, Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The dataset was downloaded from Mapzen: https://mapzen.com/data/metro-extracts/metro/perth_australia/\n",
    "\n",
    "This is a metro extract of Perth, WA, Australia. Size of 254MB with the remaining sample file to be ~50MB.\n",
    "\n",
    "I've chosen Perth as I have been living there briefly when I was a student, and have some fond memories of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- code from the course Case Sudy\n",
    "- blog posts from discussions.udacity.com\n",
    "- for the conversion from XLM to CSV and CSV to SQL I used the following GitHub as a reference: https://gist.github.com/swwelch/f1144229848b407e0a5d13fcb7fbbd6f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hide code cells\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set up libraries\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import codecs\n",
    "\n",
    "import cerberus\n",
    "import schema\n",
    "\n",
    "import os\n",
    "from hurry.filesize import size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %load 'schema.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once downloaded and unzipped, the OSM file for Perth, Australia has a size 254 MB.\n",
    "The requirement for this project is a size of 50 MB. Hence I am using the code provided in the Project Overview to create a sample file, by iterating over the lines by k buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "from pprint import pprint\n",
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "\n",
    "OSM_FILE = \"perth_australia.osm\"\n",
    "SAMPLE_FILE = \"perth_australia_sample.osm\"\n",
    "\n",
    "k = 5\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "        \n",
    "        \n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write(b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write(b'<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write(b'</osm>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The resulting sample file has a size of 51.5 MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# opening file in filename\n",
    "filename = open(\"perth_australia_sample.osm\", \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data Audit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tag types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Count of each of the tags in the OSM data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'member': 2630,\n",
       " 'nd': 302128,\n",
       " 'node': 245081,\n",
       " 'osm': 1,\n",
       " 'relation': 418,\n",
       " 'tag': 80483,\n",
       " 'way': 29385}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterative parsing from the problem set in the course\n",
    "\"\"\"\n",
    "Your task is to use the iterative parsing to process the map file and find out not only what tags are there, but also how many, \n",
    "to get the feeling on how much of which data you can expect to have in the map.\n",
    "Fill out the count_tags function. It should return a dictionary with the tag name as the key and number of times this tag can be\n",
    "encountered in the map as value.\n",
    "\"\"\"\n",
    "def count_tags(samplefile):\n",
    "    tags = {}\n",
    "    for event, element in ET.iterparse(samplefile):\n",
    "        if element.tag not in tags.keys():\n",
    "            tags[element.tag] = 1\n",
    "        else:\n",
    "            tags[element.tag] += 1\n",
    "    return tags\n",
    "\n",
    "count_tags(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We would like to change the data model and expand the \"addr:street\" type of keys to a dictionary like this:\n",
    "{\"address\": {\"street\": \"Some value\"}}\n",
    "So, we have to see if we have such tags, and if we have any tags with problematic characters.\n",
    "\n",
    "Below we have a count of each of four tag categories in a dictionary:\n",
    "  \"lower\", for tags that contain only lowercase letters and are valid,\n",
    "  \"lower_colon\", for otherwise valid tags with a colon in their names,\n",
    "  \"problemchars\", for tags with problematic characters, and\n",
    "  \"other\", for other tags that do not fall into the other three categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 70615, 'lower_colon': 9750, 'other': 118, 'problemchars': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tag types from the problem set in the course\n",
    "\"\"\"\n",
    "Your task is to explore the data a bit more. Before you process the data and add it into your database, you should check the\n",
    "\"k\" value for each \"<tag>\" and see if there are any potential problems.\n",
    "\n",
    "We have provided you with 3 regular expressions to check for certain patterns in the tags. As we saw in the quiz earlier, \n",
    "we would like to change the data model and expand the \"addr:street\" type of keys to a dictionary like this:\n",
    "{\"address\": {\"street\": \"Some value\"}}\n",
    "So, we have to see if we have such tags, and if we have any tags with problematic characters.\n",
    "\n",
    "Please complete the function 'key_type', such that we have a count of each of four tag categories in a dictionary:\n",
    "  \"lower\", for tags that contain only lowercase letters and are valid,\n",
    "  \"lower_colon\", for otherwise valid tags with a colon in their names,\n",
    "  \"problemchars\", for tags with problematic characters, and\n",
    "  \"other\", for other tags that do not fall into the other three categories.\n",
    "\"\"\"\n",
    "OSMFILE = \"perth_australia_sample.osm\"\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        k = element.attrib['k']\n",
    "        if problemchars.search(k):\n",
    "            keys['problemchars'] += 1\n",
    "        elif lower_colon.search(k):\n",
    "            keys['lower_colon'] += 1\n",
    "        elif lower.search(k):\n",
    "            keys['lower'] += 1\n",
    "        else:\n",
    "            keys['other'] += 1\n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def process_map(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(osm_file):\n",
    "        keys = key_type(element, keys)\n",
    "    osm_file.close()\n",
    "    return keys\n",
    "\n",
    "process_map(OSMFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Explore users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Below is a set of how many unique users have contributed to the map in this particular area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['1007825',\n",
      "     '1023527',\n",
      "     '1024289',\n",
      "     '1030',\n",
      "     '1030833',\n",
      "     '103253',\n",
      "     '10340',\n",
      "     '103574',\n",
      "     '103855',\n",
      "     '10412',\n",
      "     '10466',\n",
      "     '1048086',\n",
      "     '1051550',\n",
      "     '105946',\n",
      "     '106230',\n",
      "     '1069176',\n",
      "     '107612',\n",
      "     '108081',\n",
      "     '1087084',\n",
      "     '1091296',\n",
      "     '10919',\n",
      "     '1092114',\n",
      "     '1098559',\n",
      "     '110263',\n",
      "     '110283',\n",
      "     '110639',\n",
      "     '11111',\n",
      "     '111508',\n",
      "     '111529',\n",
      "     '1122708',\n",
      "     '112350',\n",
      "     '1137765',\n",
      "     '114778',\n",
      "     '1164',\n",
      "     '117927',\n",
      "     '118134',\n",
      "     '1187510',\n",
      "     '118797',\n",
      "     '1195129',\n",
      "     '119727',\n",
      "     '1200195',\n",
      "     '1209045',\n",
      "     '1215404',\n",
      "     '1219875',\n",
      "     '12203',\n",
      "     '1225082',\n",
      "     '1225165',\n",
      "     '122710',\n",
      "     '1228735',\n",
      "     '1232833',\n",
      "     '123364',\n",
      "     '1235491',\n",
      "     '1240849',\n",
      "     '1242481',\n",
      "     '124310',\n",
      "     '1244452',\n",
      "     '124815',\n",
      "     '1249205',\n",
      "     '125249',\n",
      "     '127777',\n",
      "     '1279506',\n",
      "     '128148',\n",
      "     '128186',\n",
      "     '128470',\n",
      "     '1293194',\n",
      "     '130472',\n",
      "     '1306',\n",
      "     '1318905',\n",
      "     '131918',\n",
      "     '13203',\n",
      "     '132624',\n",
      "     '133729',\n",
      "     '134344',\n",
      "     '134501',\n",
      "     '134872',\n",
      "     '134921',\n",
      "     '135851',\n",
      "     '137159',\n",
      "     '1376913',\n",
      "     '138022',\n",
      "     '1406649',\n",
      "     '1408784',\n",
      "     '1418137',\n",
      "     '1420318',\n",
      "     '142807',\n",
      "     '142831',\n",
      "     '1430982',\n",
      "     '143129',\n",
      "     '145144',\n",
      "     '1451625',\n",
      "     '145231',\n",
      "     '1453327',\n",
      "     '145881',\n",
      "     '1461056',\n",
      "     '146282',\n",
      "     '146309',\n",
      "     '1466296',\n",
      "     '1466656',\n",
      "     '1467940',\n",
      "     '147510',\n",
      "     '14779',\n",
      "     '147977',\n",
      "     '1480942',\n",
      "     '1488716',\n",
      "     '149097',\n",
      "     '149741',\n",
      "     '150565',\n",
      "     '150747',\n",
      "     '152074',\n",
      "     '152106',\n",
      "     '1522282',\n",
      "     '152289',\n",
      "     '1536865',\n",
      "     '1554480',\n",
      "     '155462',\n",
      "     '1556219',\n",
      "     '156191',\n",
      "     '1578574',\n",
      "     '1581410',\n",
      "     '1589252',\n",
      "     '159101',\n",
      "     '160229',\n",
      "     '161619',\n",
      "     '161871',\n",
      "     '162109',\n",
      "     '163045',\n",
      "     '16385',\n",
      "     '16558',\n",
      "     '165869',\n",
      "     '167545',\n",
      "     '1679',\n",
      "     '1681010',\n",
      "     '168136',\n",
      "     '1686461',\n",
      "     '1694420',\n",
      "     '1695910',\n",
      "     '169731',\n",
      "     '1703458',\n",
      "     '1711446',\n",
      "     '1715475',\n",
      "     '17196',\n",
      "     '172061',\n",
      "     '1725154',\n",
      "     '1726337',\n",
      "     '1727246',\n",
      "     '172952',\n",
      "     '1734',\n",
      "     '1739827',\n",
      "     '174216',\n",
      "     '1743262',\n",
      "     '17497',\n",
      "     '1756898',\n",
      "     '176224',\n",
      "     '1762683',\n",
      "     '1765723',\n",
      "     '1767145',\n",
      "     '1772801',\n",
      "     '177503',\n",
      "     '1778799',\n",
      "     '178186',\n",
      "     '1786353',\n",
      "     '1787943',\n",
      "     '1801711',\n",
      "     '18106',\n",
      "     '181131',\n",
      "     '181135',\n",
      "     '1813535',\n",
      "     '18170',\n",
      "     '18174',\n",
      "     '1824494',\n",
      "     '1829683',\n",
      "     '1830192',\n",
      "     '1841557',\n",
      "     '184263',\n",
      "     '18459',\n",
      "     '18520',\n",
      "     '1852029',\n",
      "     '186367',\n",
      "     '1864301',\n",
      "     '1869566',\n",
      "     '1869800',\n",
      "     '1871462',\n",
      "     '1871582',\n",
      "     '1884293',\n",
      "     '1884355',\n",
      "     '18846',\n",
      "     '1885087',\n",
      "     '1885118',\n",
      "     '1885188',\n",
      "     '1889162',\n",
      "     '189263',\n",
      "     '1905062',\n",
      "     '190869',\n",
      "     '1913547',\n",
      "     '1915697',\n",
      "     '191970',\n",
      "     '192521',\n",
      "     '1925340',\n",
      "     '192564',\n",
      "     '192584',\n",
      "     '1937469',\n",
      "     '1944276',\n",
      "     '194728',\n",
      "     '195966',\n",
      "     '1964167',\n",
      "     '1964769',\n",
      "     '196617',\n",
      "     '197741',\n",
      "     '197933',\n",
      "     '19799',\n",
      "     '1982092',\n",
      "     '1988610',\n",
      "     '199300',\n",
      "     '1997532',\n",
      "     '1999443',\n",
      "     '2007590',\n",
      "     '200997',\n",
      "     '201359',\n",
      "     '2020693',\n",
      "     '202356',\n",
      "     '203359',\n",
      "     '2034065',\n",
      "     '2035624',\n",
      "     '20358',\n",
      "     '2051201',\n",
      "     '2068953',\n",
      "     '207745',\n",
      "     '2083295',\n",
      "     '208709',\n",
      "     '2092525',\n",
      "     '2098546',\n",
      "     '21115',\n",
      "     '211503',\n",
      "     '2115749',\n",
      "     '212042',\n",
      "     '212196',\n",
      "     '21228',\n",
      "     '2133',\n",
      "     '213594',\n",
      "     '214375',\n",
      "     '214657',\n",
      "     '215053',\n",
      "     '215398',\n",
      "     '215807',\n",
      "     '216239',\n",
      "     '2166279',\n",
      "     '2172916',\n",
      "     '2178793',\n",
      "     '2178819',\n",
      "     '218114',\n",
      "     '2185493',\n",
      "     '218941',\n",
      "     '220430',\n",
      "     '2209894',\n",
      "     '2219338',\n",
      "     '2226712',\n",
      "     '223157',\n",
      "     '2238952',\n",
      "     '2246805',\n",
      "     '2254485',\n",
      "     '2254673',\n",
      "     '225778',\n",
      "     '2268702',\n",
      "     '22727',\n",
      "     '2282197',\n",
      "     '2290292',\n",
      "     '2299575',\n",
      "     '2301817',\n",
      "     '231359',\n",
      "     '2318',\n",
      "     '235098',\n",
      "     '23549',\n",
      "     '2356585',\n",
      "     '23630',\n",
      "     '2367929',\n",
      "     '2371140',\n",
      "     '237525',\n",
      "     '2377377',\n",
      "     '237935',\n",
      "     '2396101',\n",
      "     '2398635',\n",
      "     '239998',\n",
      "     '2407218',\n",
      "     '240843',\n",
      "     '24119',\n",
      "     '24126',\n",
      "     '2414348',\n",
      "     '241462',\n",
      "     '242497',\n",
      "     '2425579',\n",
      "     '242915',\n",
      "     '2429841',\n",
      "     '24304',\n",
      "     '2438579',\n",
      "     '2440726',\n",
      "     '2450079',\n",
      "     '2456566',\n",
      "     '24614',\n",
      "     '2473771',\n",
      "     '248077',\n",
      "     '2482315',\n",
      "     '2488167',\n",
      "     '24965',\n",
      "     '250487',\n",
      "     '2508151',\n",
      "     '2511706',\n",
      "     '2512300',\n",
      "     '251543',\n",
      "     '2520758',\n",
      "     '2537642',\n",
      "     '2550984',\n",
      "     '2554698',\n",
      "     '2558808',\n",
      "     '25646',\n",
      "     '256960',\n",
      "     '258497',\n",
      "     '2607470',\n",
      "     '260772',\n",
      "     '260798',\n",
      "     '261730',\n",
      "     '2622285',\n",
      "     '2632564',\n",
      "     '2639622',\n",
      "     '2644101',\n",
      "     '2645991',\n",
      "     '26526',\n",
      "     '265659',\n",
      "     '2666290',\n",
      "     '2680409',\n",
      "     '2692165',\n",
      "     '27247',\n",
      "     '274723',\n",
      "     '2748195',\n",
      "     '2758',\n",
      "     '275821',\n",
      "     '2778924',\n",
      "     '2800919',\n",
      "     '280397',\n",
      "     '280679',\n",
      "     '2813431',\n",
      "     '28334',\n",
      "     '2835928',\n",
      "     '284466',\n",
      "     '2847988',\n",
      "     '285062',\n",
      "     '285436',\n",
      "     '28559',\n",
      "     '2863129',\n",
      "     '286648',\n",
      "     '2874541',\n",
      "     '2875074',\n",
      "     '2877856',\n",
      "     '28794',\n",
      "     '2882841',\n",
      "     '2886128',\n",
      "     '288795',\n",
      "     '289121',\n",
      "     '2902259',\n",
      "     '2902356',\n",
      "     '2905914',\n",
      "     '290680',\n",
      "     '2908567',\n",
      "     '2910757',\n",
      "     '2925383',\n",
      "     '292795',\n",
      "     '293158',\n",
      "     '294850',\n",
      "     '2955920',\n",
      "     '295855',\n",
      "     '2958964',\n",
      "     '296075',\n",
      "     '2960866',\n",
      "     '2963768',\n",
      "     '2978389',\n",
      "     '299132',\n",
      "     '2998023',\n",
      "     '3007126',\n",
      "     '30107',\n",
      "     '3011093',\n",
      "     '3022452',\n",
      "     '302890',\n",
      "     '303821',\n",
      "     '3046817',\n",
      "     '3051431',\n",
      "     '3053956',\n",
      "     '306817',\n",
      "     '3074520',\n",
      "     '307520',\n",
      "     '3077038',\n",
      "     '308',\n",
      "     '308353',\n",
      "     '308809',\n",
      "     '3114',\n",
      "     '3119906',\n",
      "     '31231',\n",
      "     '3137708',\n",
      "     '313848',\n",
      "     '3153435',\n",
      "     '3158594',\n",
      "     '3164012',\n",
      "     '317634',\n",
      "     '3178375',\n",
      "     '3182642',\n",
      "     '3184318',\n",
      "     '318506',\n",
      "     '3189408',\n",
      "     '3195374',\n",
      "     '3197593',\n",
      "     '320632',\n",
      "     '3217483',\n",
      "     '322052',\n",
      "     '322111',\n",
      "     '322422',\n",
      "     '324131',\n",
      "     '3243536',\n",
      "     '325087',\n",
      "     '3253070',\n",
      "     '3272286',\n",
      "     '32729',\n",
      "     '32810',\n",
      "     '328403',\n",
      "     '328442',\n",
      "     '328920',\n",
      "     '3291024',\n",
      "     '3294946',\n",
      "     '32952',\n",
      "     '3295418',\n",
      "     '330274',\n",
      "     '3311043',\n",
      "     '3315646',\n",
      "     '3329969',\n",
      "     '3342374',\n",
      "     '3343025',\n",
      "     '336460',\n",
      "     '336598',\n",
      "     '336641',\n",
      "     '337457',\n",
      "     '3378008',\n",
      "     '338402',\n",
      "     '338866',\n",
      "     '339581',\n",
      "     '3400085',\n",
      "     '3401480',\n",
      "     '34107',\n",
      "     '341519',\n",
      "     '342292',\n",
      "     '3431433',\n",
      "     '343537',\n",
      "     '344126',\n",
      "     '3448415',\n",
      "     '3462244',\n",
      "     '346429',\n",
      "     '3468293',\n",
      "     '3472625',\n",
      "     '347944',\n",
      "     '349913',\n",
      "     '350119',\n",
      "     '3508344',\n",
      "     '3518066',\n",
      "     '3526564',\n",
      "     '355242',\n",
      "     '3562059',\n",
      "     '356473',\n",
      "     '356586',\n",
      "     '3576278',\n",
      "     '3582243',\n",
      "     '358666',\n",
      "     '360392',\n",
      "     '360544',\n",
      "     '3616366',\n",
      "     '3619603',\n",
      "     '36235',\n",
      "     '3672376',\n",
      "     '371',\n",
      "     '37125',\n",
      "     '3719008',\n",
      "     '372169',\n",
      "     '373491',\n",
      "     '374310',\n",
      "     '374471',\n",
      "     '3752553',\n",
      "     '375689',\n",
      "     '3761925',\n",
      "     '3797097',\n",
      "     '3818047',\n",
      "     '3819561',\n",
      "     '3820261',\n",
      "     '38313',\n",
      "     '3837003',\n",
      "     '3846096',\n",
      "     '385027',\n",
      "     '386614',\n",
      "     '3877019',\n",
      "     '3880251',\n",
      "     '3882783',\n",
      "     '388810',\n",
      "     '389362',\n",
      "     '389397',\n",
      "     '3910057',\n",
      "     '3915626',\n",
      "     '3918003',\n",
      "     '392121',\n",
      "     '3929827',\n",
      "     '3938483',\n",
      "     '3950326',\n",
      "     '39504',\n",
      "     '3972974',\n",
      "     '398946',\n",
      "     '3990291',\n",
      "     '3994633',\n",
      "     '4000368',\n",
      "     '4029500',\n",
      "     '4040082',\n",
      "     '404532',\n",
      "     '4077997',\n",
      "     '4081528',\n",
      "     '409195',\n",
      "     '4110199',\n",
      "     '4115745',\n",
      "     '4131286',\n",
      "     '415883',\n",
      "     '4176176',\n",
      "     '417869',\n",
      "     '4181572',\n",
      "     '4181929',\n",
      "     '418724',\n",
      "     '42191',\n",
      "     '4220506',\n",
      "     '4222661',\n",
      "     '422271',\n",
      "     '4224085',\n",
      "     '424110',\n",
      "     '4270959',\n",
      "     '4272183',\n",
      "     '427914',\n",
      "     '429325',\n",
      "     '430337',\n",
      "     '430683',\n",
      "     '432297',\n",
      "     '432375',\n",
      "     '43373',\n",
      "     '435169',\n",
      "     '4359362',\n",
      "     '436238',\n",
      "     '4368209',\n",
      "     '4375371',\n",
      "     '437598',\n",
      "     '438078',\n",
      "     '4380864',\n",
      "     '4388',\n",
      "     '438898',\n",
      "     '439883',\n",
      "     '440413',\n",
      "     '4414128',\n",
      "     '44217',\n",
      "     '44221',\n",
      "     '4428830',\n",
      "     '4461367',\n",
      "     '4462259',\n",
      "     '4467',\n",
      "     '448254',\n",
      "     '45027',\n",
      "     '4516353',\n",
      "     '4529819',\n",
      "     '4532687',\n",
      "     '4568470',\n",
      "     '4576',\n",
      "     '4602901',\n",
      "     '460320',\n",
      "     '46052',\n",
      "     '462207',\n",
      "     '4624424',\n",
      "     '4630609',\n",
      "     '464253',\n",
      "     '46482',\n",
      "     '467',\n",
      "     '467117',\n",
      "     '4682012',\n",
      "     '470034',\n",
      "     '470228',\n",
      "     '472067',\n",
      "     '4721346',\n",
      "     '474310',\n",
      "     '4746053',\n",
      "     '47565',\n",
      "     '4772572',\n",
      "     '4779670',\n",
      "     '479290',\n",
      "     '4795494',\n",
      "     '47978',\n",
      "     '4813571',\n",
      "     '481533',\n",
      "     '481865',\n",
      "     '4820528',\n",
      "     '4826435',\n",
      "     '483947',\n",
      "     '484544',\n",
      "     '4847896',\n",
      "     '485152',\n",
      "     '4872372',\n",
      "     '4889985',\n",
      "     '4892871',\n",
      "     '49111',\n",
      "     '4911491',\n",
      "     '4916303',\n",
      "     '4921676',\n",
      "     '493595',\n",
      "     '4939488',\n",
      "     '4940632',\n",
      "     '4943419',\n",
      "     '4947915',\n",
      "     '4948452',\n",
      "     '4991',\n",
      "     '4992',\n",
      "     '4993617',\n",
      "     '499672',\n",
      "     '5007159',\n",
      "     '5007973',\n",
      "     '5008487',\n",
      "     '5009070',\n",
      "     '5009267',\n",
      "     '5009407',\n",
      "     '5009725',\n",
      "     '5010333',\n",
      "     '5010351',\n",
      "     '5010545',\n",
      "     '5012334',\n",
      "     '5014625',\n",
      "     '5016118',\n",
      "     '5052358',\n",
      "     '505681',\n",
      "     '5058820',\n",
      "     '5059751',\n",
      "     '506275',\n",
      "     '5073399',\n",
      "     '507464',\n",
      "     '508',\n",
      "     '5083788',\n",
      "     '5086461',\n",
      "     '510836',\n",
      "     '5136672',\n",
      "     '5136679',\n",
      "     '5146791',\n",
      "     '5147086',\n",
      "     '514909',\n",
      "     '5152262',\n",
      "     '5157894',\n",
      "     '516303',\n",
      "     '5164',\n",
      "     '51722',\n",
      "     '5179917',\n",
      "     '5184943',\n",
      "     '5185134',\n",
      "     '5186284',\n",
      "     '5186989',\n",
      "     '5188665',\n",
      "     '5188852',\n",
      "     '5189049',\n",
      "     '5189191',\n",
      "     '5193349',\n",
      "     '5203619',\n",
      "     '5205074',\n",
      "     '5205507',\n",
      "     '5205654',\n",
      "     '5205953',\n",
      "     '5208263',\n",
      "     '5211694',\n",
      "     '5211904',\n",
      "     '5213111',\n",
      "     '5213995',\n",
      "     '5219030',\n",
      "     '522383',\n",
      "     '5225461',\n",
      "     '5228586',\n",
      "     '5237592',\n",
      "     '524500',\n",
      "     '5254110',\n",
      "     '5273533',\n",
      "     '5289831',\n",
      "     '5295350',\n",
      "     '5302690',\n",
      "     '5332798',\n",
      "     '533465',\n",
      "     '5339535',\n",
      "     '534142',\n",
      "     '5348907',\n",
      "     '5359',\n",
      "     '5363504',\n",
      "     '5363873',\n",
      "     '5380763',\n",
      "     '541109',\n",
      "     '5412038',\n",
      "     '5412168',\n",
      "     '5413429',\n",
      "     '5418632',\n",
      "     '5418633',\n",
      "     '5418655',\n",
      "     '5418663',\n",
      "     '5419496',\n",
      "     '5423179',\n",
      "     '5438123',\n",
      "     '54438',\n",
      "     '5452644',\n",
      "     '5453215',\n",
      "     '5453322',\n",
      "     '5453625',\n",
      "     '5453633',\n",
      "     '5453654',\n",
      "     '5453703',\n",
      "     '5453725',\n",
      "     '5453741',\n",
      "     '5453748',\n",
      "     '5453757',\n",
      "     '5453859',\n",
      "     '5453862',\n",
      "     '5453903',\n",
      "     '5454009',\n",
      "     '5454045',\n",
      "     '5454341',\n",
      "     '5454923',\n",
      "     '5454969',\n",
      "     '5455650',\n",
      "     '5455825',\n",
      "     '5459024',\n",
      "     '546475',\n",
      "     '5465584',\n",
      "     '5467662',\n",
      "     '5468964',\n",
      "     '5470087',\n",
      "     '5475460',\n",
      "     '5481091',\n",
      "     '5487171',\n",
      "     '5509679',\n",
      "     '5520108',\n",
      "     '5570896',\n",
      "     '557956',\n",
      "     '5589431',\n",
      "     '5596311',\n",
      "     '560730',\n",
      "     '5638805',\n",
      "     '56438',\n",
      "     '5653973',\n",
      "     '5674237',\n",
      "     '5677293',\n",
      "     '5694636',\n",
      "     '5694706',\n",
      "     '571888',\n",
      "     '5723232',\n",
      "     '5724212',\n",
      "     '57380',\n",
      "     '574654',\n",
      "     '575605',\n",
      "     '576259',\n",
      "     '577497',\n",
      "     '578234',\n",
      "     '581277',\n",
      "     '581284',\n",
      "     '583894',\n",
      "     '58949',\n",
      "     '599841',\n",
      "     '600859',\n",
      "     '602138',\n",
      "     '60233',\n",
      "     '602634',\n",
      "     '6066236',\n",
      "     '607818',\n",
      "     '6103839',\n",
      "     '6116100',\n",
      "     '611863',\n",
      "     '612986',\n",
      "     '613088',\n",
      "     '6154624',\n",
      "     '616774',\n",
      "     '617246',\n",
      "     '617303',\n",
      "     '617307',\n",
      "     '61942',\n",
      "     '6200428',\n",
      "     '6204544',\n",
      "     '6205282',\n",
      "     '622950',\n",
      "     '627255',\n",
      "     '6286349',\n",
      "     '6293534',\n",
      "     '6322557',\n",
      "     '633674',\n",
      "     '633917',\n",
      "     '6373078',\n",
      "     '641172',\n",
      "     '642594',\n",
      "     '6439963',\n",
      "     '6453998',\n",
      "     '6459358',\n",
      "     '6464783',\n",
      "     '6502427',\n",
      "     '650272',\n",
      "     '65032',\n",
      "     '6506373',\n",
      "     '651869',\n",
      "     '652072',\n",
      "     '652598',\n",
      "     '65264',\n",
      "     '65357',\n",
      "     '658125',\n",
      "     '66068',\n",
      "     '6607596',\n",
      "     '662136',\n",
      "     '662170',\n",
      "     '6628578',\n",
      "     '663232',\n",
      "     '6645204',\n",
      "     '6645608',\n",
      "     '667422',\n",
      "     '66811',\n",
      "     '668313',\n",
      "     '6703715',\n",
      "     '6718134',\n",
      "     '6719766',\n",
      "     '6738144',\n",
      "     '6775387',\n",
      "     '67862',\n",
      "     '67896',\n",
      "     '6800306',\n",
      "     '6804779',\n",
      "     '682281',\n",
      "     '68665',\n",
      "     '687237',\n",
      "     '6880278',\n",
      "     '6897503',\n",
      "     '6900040',\n",
      "     '69102',\n",
      "     '6912181',\n",
      "     '691220',\n",
      "     '692576',\n",
      "     '692899',\n",
      "     '693098',\n",
      "     '695510',\n",
      "     '6957160',\n",
      "     '6975',\n",
      "     '6976752',\n",
      "     '69853',\n",
      "     '69959',\n",
      "     '701372',\n",
      "     '70696',\n",
      "     '7079208',\n",
      "     '711559',\n",
      "     '712208',\n",
      "     '71283',\n",
      "     '7131972',\n",
      "     '722137',\n",
      "     '72389',\n",
      "     '72613',\n",
      "     '726574',\n",
      "     '726700',\n",
      "     '73319',\n",
      "     '735',\n",
      "     '74036',\n",
      "     '7437',\n",
      "     '74617',\n",
      "     '7523',\n",
      "     '755114',\n",
      "     '756657',\n",
      "     '7568',\n",
      "     '76002',\n",
      "     '76592',\n",
      "     '76752',\n",
      "     '76826',\n",
      "     '76950',\n",
      "     '77221',\n",
      "     '7806',\n",
      "     '78060',\n",
      "     '78656',\n",
      "     '78837',\n",
      "     '79165',\n",
      "     '79475',\n",
      "     '80215',\n",
      "     '810529',\n",
      "     '818189',\n",
      "     '832066',\n",
      "     '84644',\n",
      "     '84853',\n",
      "     '84937',\n",
      "     '85218',\n",
      "     '854840',\n",
      "     '8586',\n",
      "     '85951',\n",
      "     '87720',\n",
      "     '895760',\n",
      "     '898109',\n",
      "     '90142',\n",
      "     '902985',\n",
      "     '9060',\n",
      "     '90768',\n",
      "     '908784',\n",
      "     '91490',\n",
      "     '91541',\n",
      "     '91740',\n",
      "     '92274',\n",
      "     '935037',\n",
      "     '936036',\n",
      "     '943785',\n",
      "     '94381',\n",
      "     '94578',\n",
      "     '945898',\n",
      "     '9499',\n",
      "     '95751',\n",
      "     '960426',\n",
      "     '96046',\n",
      "     '96069',\n",
      "     '971670',\n",
      "     '9719',\n",
      "     '982380',\n",
      "     '983176',\n",
      "     '98448',\n",
      "     '98877'])\n"
     ]
    }
   ],
   "source": [
    "# Exploring Users from the problem set in the course\n",
    "\n",
    "\"\"\"\n",
    "Your task is to explore the data a bit more.\n",
    "The first task is a fun one - find out how many unique users\n",
    "have contributed to the map in this particular area!\n",
    "\n",
    "The function process_map should return a set of unique user IDs (\"uid\")\n",
    "\"\"\"\n",
    "OSMFILE = \"perth_australia_sample.osm\"\n",
    "def process_map(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(osm_file):\n",
    "        tag = element.tag\n",
    "        if tag in [ 'node', 'way', 'relation']:\n",
    "\n",
    "            id = element.attrib['uid']\n",
    "            users.add(id)\n",
    "        pass\n",
    "    osm_file.close()\n",
    "    return users\n",
    "\n",
    "users = process_map(OSMFILE)\n",
    "pprint.pprint(users)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now that we have the data ready, we will start to audit and correct some of the mistakes identified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Audit and correct streetnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The first step is to look at the street names of the dataset, with the tag \"addr:street\". For this we take a list of the street types we expect to have for Perth:\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Highway\", \"Way\", \"Freeway\", \"Crossing\", \"Mall\", \"Loop\", \"Circle\", \"Crescent\", \"Gate\", \"Close\",\n",
    "           \"Mews\", \"Parade\", \"Terrace\"]\n",
    "\n",
    "And then we compare this list with all the street types that actually exist in our sample OSM for Perth. Each anomaly is included in the below dictionary with their occurence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Arcade': set([\"St Martin's Arcade\"]),\n",
      " 'Boulevarde': set(['Grand Boulevarde']),\n",
      " 'Broadway': set(['The Broadway']),\n",
      " 'Caversham': set(['Lot 41 - 1 Mavro Street, Caversham']),\n",
      " 'Circuit': set(['Catalano Circuit']),\n",
      " 'Corner': set(['Friday Corner']),\n",
      " 'Courtyard': set(['Elia Courtyard']),\n",
      " 'Cove': set(['Kelso Cove', 'Sulphur Cove', 'Tahiti Cove', 'The Cove']),\n",
      " 'Cross': set(['Cockman Cross', 'Lewis Jones Cross']),\n",
      " 'Crossway': set(['Crossway']),\n",
      " 'Ct': set([\"O'Kane Ct\"]),\n",
      " 'Dale': set(['Altai Dale', 'Woodland Dale']),\n",
      " 'East': set(['Lawnbrook Road East']),\n",
      " 'Edge': set(['Creek Edge']),\n",
      " 'Elbow': set(['Drummore Elbow', 'Hindoo Elbow', 'The Elbow']),\n",
      " 'Entrance': set(['Bombay Entrance',\n",
      "                  'Edwards Entrance',\n",
      "                  'Kangaroo Entrance',\n",
      "                  'Percheron Entrance']),\n",
      " 'Escarpment': set(['The Escarpment']),\n",
      " 'Esplanade': set(['The Esplanade']),\n",
      " 'Furniss': set(['Furniss']),\n",
      " 'Gap': set(['Pine Gap']),\n",
      " 'Garden': set(['Connaught Garden', 'Fairfield Garden']),\n",
      " 'Gardens': set(['Campolino Gardens',\n",
      "                 'Canning River Gardens',\n",
      "                 'Corsham Gardens',\n",
      "                 'Coyecup Gardens',\n",
      "                 'Fairfield Gardens',\n",
      "                 'Squires Gardens',\n",
      "                 'Wilgie Gardens']),\n",
      " 'Gelderland': set(['Gelderland']),\n",
      " 'Grade': set(['Brahmin Grade']),\n",
      " 'Green': set(['Fussel Green', 'Solway Green']),\n",
      " 'Grove': set(['Britomart Grove',\n",
      "               'Chungking Grove',\n",
      "               'Colin Grove',\n",
      "               'Garnsworthy Grove',\n",
      "               'Kybra Grove',\n",
      "               'Old Lake Grove',\n",
      "               'Sunset Grove',\n",
      "               'Trusty Grove']),\n",
      " 'Haven': set(['The Haven']),\n",
      " 'Hill': set(['Higham Hill']),\n",
      " 'Junction': set(['Pymmes Junction']),\n",
      " 'Link': set(['Prolog Link']),\n",
      " 'Morrison': set(['Morrison']),\n",
      " 'North': set(['Beechboro Road North', 'Riverton Drive North']),\n",
      " 'Parkway': set(['Marginata Parkway']),\n",
      " 'Pass': set(['Lesueur Pass', 'Oldenburg Pass', 'Shannon Pass']),\n",
      " 'Ramble': set(['The Ramble']),\n",
      " 'Retreat': set(['Borale Retreat', 'Burton Retreat', 'Koolama Retreat']),\n",
      " 'Ridgeway': set(['The Ridgeway']),\n",
      " 'Rise': set(['Amcer Rise',\n",
      "              'Biga Rise',\n",
      "              'Brilliant Rise',\n",
      "              'Gypsy Rise',\n",
      "              'Packer Rise',\n",
      "              'Robins Rise']),\n",
      " 'South': set(['Illawarra Crescent South']),\n",
      " 'St': set(['Newcastle St']),\n",
      " 'Subiaco': set(['Hay Street, Subiaco']),\n",
      " 'Turn': set(['Stainsby Turn']),\n",
      " 'University': set(['Curtin University']),\n",
      " 'Vale': set(['Simmental Vale']),\n",
      " 'View': set(['Scarp View', 'Sparrowhawk View', 'Tall Tree View']),\n",
      " 'Vista': set(['Howell Vista']),\n",
      " 'West': set(['George Street West', 'Riverton Drive West']),\n",
      " 'street': set(['oxford street'])}\n"
     ]
    }
   ],
   "source": [
    "# Create a regex for the street names as street_type_re \n",
    "# Create a default dictionary of standardized names\n",
    "# Audit the file to find alternate names\n",
    "\n",
    "OSMFILE = \"perth_australia_sample.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "street_types = defaultdict(set)\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Highway\", \"Way\", \"Freeway\", \"Crossing\", \"Mall\", \"Loop\", \"Circle\", \"Crescent\", \"Gate\", \"Close\",\n",
    "           \"Mews\", \"Parade\", \"Terrace\"]\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"way\" or elem.tag == \"node\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "\n",
    "# Run audit and print results\n",
    "st_types = audit(OSMFILE)\n",
    "pprint.pprint(dict(st_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "From the output of this audit, the data for Perth is actually pretty clean. There are only a couple of abbreviations to change (St and Ct) as well as a tag 'street' to change into 'Street' and 'Boulevarde' which is a typo for 'Boulevard'. I also find 'Subiaco' and 'Caversham', which are suburbs' names, 'Morrison' which is a Mall, 'Gelderland' which should be \"Gelderland Entrance\". Both Fairfield Garden and Connaught Garden should also have Garden spelled 'Gardens'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "However, while the 50MB portion of the initial osm file looks pretty clean, we can have other cases of abbreviated names in the full dataset. Therefore, I'll use an extensive mapping of common abbreviations to update the names. The streetnames are returned below after correction, with the format \"name => better_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"ST\": \"Street\",\n",
    "            \"st\": \"Street\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"RD\": \"Road\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Ave.\": \"Avenue\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"BLVD\": \"Boulevard\",\n",
    "            \"Cir\": \"Circle\",\n",
    "            \"Ct\": \"Court\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"Garden\": \"Gardens\",\n",
    "            \"Trl\": \"Trail\",\n",
    "            \"Ter\": \"Terrace\",\n",
    "            \"Pl\": \"Place\",\n",
    "            \"Pkwy\": \"Parkway\",\n",
    "            \"Bnd\": \"Bend\",\n",
    "            \"Mnr\": \"Manor\",\n",
    "            \"Ln\": \"Lane\",\n",
    "            \"street\": \"Street\",\n",
    "            \"AVE\": \"Avenue\",\n",
    "            \"Blvd.\": \"Boulevard\",\n",
    "            \"Cirlce\": \"Circle\",\n",
    "            \"DRIVE\": \"Drive\",\n",
    "            \"Cv\": \"Cove\",\n",
    "            \"Dr.\": \"Drive\",\n",
    "            \"Druve\": \"Drive\",\n",
    "            \"Holw\": \"Hollow\",\n",
    "            \"Hwy\": \"Highway\",\n",
    "            \"HWY\": \"Highway\",\n",
    "            \"Pt\": \"Point\",\n",
    "            \"Trce\": \"Trace\",\n",
    "            \"ave\": \"Avenue\",\n",
    "            \"Cres\": \"Crescent\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Howell Vista => Howell Vista\n",
      "St Martin's Arcade => St Martin's Arcade\n",
      "George Street West => George Street West\n",
      "Riverton Drive West => Riverton Drive West\n",
      "Cockman Cross => Cockman Cross\n",
      "Lewis Jones Cross => Lewis Jones Cross\n",
      "The Escarpment => The Escarpment\n",
      "Hay Street, Subiaco => Hay Street, Subiaco\n",
      "oxford street => oxford Street\n",
      "Higham Hill => Higham Hill\n",
      "Lawnbrook Road East => Lawnbrook Road East\n",
      "Morrison => Morrison\n",
      "Altai Dale => Altai Dale\n",
      "Woodland Dale => Woodland Dale\n",
      "Kangaroo Entrance => Kangaroo Entrance\n",
      "Percheron Entrance => Percheron Entrance\n",
      "Edwards Entrance => Edwards Entrance\n",
      "Bombay Entrance => Bombay Entrance\n",
      "Beechboro Road North => Beechboro Road North\n",
      "Riverton Drive North => Riverton Drive North\n",
      "Fairfield Garden => Fairfield Gardens\n",
      "Connaught Garden => Connaught Gardens\n",
      "Gypsy Rise => Gypsy Rise\n",
      "Biga Rise => Biga Rise\n",
      "Packer Rise => Packer Rise\n",
      "Robins Rise => Robins Rise\n",
      "Brilliant Rise => Brilliant Rise\n",
      "Amcer Rise => Amcer Rise\n",
      "Tahiti Cove => Tahiti Cove\n",
      "Sulphur Cove => Sulphur Cove\n",
      "The Cove => The Cove\n",
      "Kelso Cove => Kelso Cove\n",
      "Simmental Vale => Simmental Vale\n",
      "Pine Gap => Pine Gap\n",
      "Elia Courtyard => Elia Courtyard\n",
      "Lot 41 - 1 Mavro Street, Caversham => Lot 41 - 1 Mavro Street, Caversham\n",
      "Prolog Link => Prolog Link\n",
      "Crossway => Crossway\n",
      "The Haven => The Haven\n",
      "Koolama Retreat => Koolama Retreat\n",
      "Burton Retreat => Burton Retreat\n",
      "Borale Retreat => Borale Retreat\n",
      "Furniss => Furniss\n",
      "The Ridgeway => The Ridgeway\n",
      "Colin Grove => Colin Grove\n",
      "Chungking Grove => Chungking Grove\n",
      "Garnsworthy Grove => Garnsworthy Grove\n",
      "Kybra Grove => Kybra Grove\n",
      "Sunset Grove => Sunset Grove\n",
      "Britomart Grove => Britomart Grove\n",
      "Old Lake Grove => Old Lake Grove\n",
      "Trusty Grove => Trusty Grove\n",
      "Curtin University => Curtin University\n",
      "Newcastle St => Newcastle Street\n",
      "Stainsby Turn => Stainsby Turn\n",
      "Creek Edge => Creek Edge\n",
      "Solway Green => Solway Green\n",
      "Fussel Green => Fussel Green\n",
      "Catalano Circuit => Catalano Circuit\n",
      "Friday Corner => Friday Corner\n",
      "Drummore Elbow => Drummore Elbow\n",
      "Hindoo Elbow => Hindoo Elbow\n",
      "The Elbow => The Elbow\n",
      "Gelderland => Gelderland\n",
      "Marginata Parkway => Marginata Parkway\n",
      "Squires Gardens => Squires Gardens\n",
      "Campolino Gardens => Campolino Gardens\n",
      "Fairfield Gardens => Fairfield Gardens\n",
      "Coyecup Gardens => Coyecup Gardens\n",
      "Wilgie Gardens => Wilgie Gardens\n",
      "Canning River Gardens => Canning River Gardens\n",
      "Corsham Gardens => Corsham Gardens\n",
      "Illawarra Crescent South => Illawarra Crescent South\n",
      "Tall Tree View => Tall Tree View\n",
      "Scarp View => Scarp View\n",
      "Sparrowhawk View => Sparrowhawk View\n",
      "The Ramble => The Ramble\n",
      "Brahmin Grade => Brahmin Grade\n",
      "The Esplanade => The Esplanade\n",
      "Grand Boulevarde => Grand Boulevarde\n",
      "Pymmes Junction => Pymmes Junction\n",
      "Shannon Pass => Shannon Pass\n",
      "Oldenburg Pass => Oldenburg Pass\n",
      "Lesueur Pass => Lesueur Pass\n",
      "The Broadway => The Broadway\n",
      "O'Kane Ct => O'Kane Court\n"
     ]
    }
   ],
   "source": [
    "def update_name(name, mapping):\n",
    "    \"\"\" Substitutes incorrect abbreviation with correct one. \"\"\"\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        temp= 0\n",
    "        try:\n",
    "            temp = int(street_type)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if street_type not in expected and temp == 0:\n",
    "            try:\n",
    "                name = re.sub(street_type_re, mapping[street_type], name)\n",
    "            except:\n",
    "                pass\n",
    "    return name\n",
    "\n",
    "for st_type, ways in st_types.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping)\n",
    "        print name, \"=>\", better_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Audit and correct postcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next I'll look into the postcodes: Perth postcodes are 4 digit-numbers starting by 6. Using similar functions than the section on streetnames, we can look for unusual postcodes as printed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WA 6162', 'WA 6000', 'WA 6107', 'WA 6156', 'WA 6156']\n"
     ]
    }
   ],
   "source": [
    "# # Create a group of auditing functions for postal codes\n",
    "def audit_postcode(post_code, digits):\n",
    "    \"\"\" Checks if postal code is incompatible and adds it to the list if so. \"\"\"\n",
    "    if len(digits) != 4 or digits[0] != '6':\n",
    "        post_code.append(digits)\n",
    "\n",
    "\n",
    "def is_postalcode(elem):\n",
    "    \"\"\" Returns a Boolean value.\"\"\"\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    \"\"\" Iterates and returns list of inconsistent postal codes found in the document. \"\"\"\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    post_code = []\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_postalcode(tag):\n",
    "                    audit_postcode(post_code, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return post_code\n",
    "\n",
    "# Run audit and print results\n",
    "postal_codes = audit(OSMFILE)\n",
    "print postal_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here WA stands for Western Australia. While those are correct postcodes, we can remove the letters and spaces to harmonize their format with the rest of the dataset. After a similar update process than for the street names, the unusual postcodes are corrected as per below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WA 6162 => 6162\n",
      "WA 6000 => 6000\n",
      "WA 6107 => 6107\n",
      "WA 6156 => 6156\n",
      "WA 6156 => 6156\n"
     ]
    }
   ],
   "source": [
    "def update_zipcode(post_code):    \n",
    "    if post_code[0:2] == 'WA' or post_code[0:2] == 'Wa' or post_code[0:2] == 'wa':\n",
    "        post_code = post_code[3:].strip()\n",
    "    return post_code\n",
    "\n",
    "for code in postal_codes:\n",
    "    better_code = update_zipcode(code)\n",
    "    print code, \"=>\", better_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convert XLM to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we can transform the data into CSV files ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Preparing for Database from the problem set in the course\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Check if input element is a \"node\" or a \"way\" then clean, shape and parse to corresponding dictionary.\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "    \n",
    "    if element.tag == 'node':\n",
    "        for field in node_attr_fields:\n",
    "            node_attribs[field] = element.attrib[field]\n",
    "    \n",
    "    if element.tag == 'way':\n",
    "        for field in way_attr_fields:\n",
    "            way_attribs[field] = element.attrib[field]\n",
    "        \n",
    "        position = 0\n",
    "        temp = {}\n",
    "        for tag in element.iter(\"nd\"):\n",
    "            temp['id'] = element.attrib[\"id\"]\n",
    "            temp['node_id'] = tag.attrib[\"ref\"]\n",
    "            temp['position'] = position\n",
    "            position += 1\n",
    "            way_nodes.append(temp.copy())\n",
    "\n",
    "    temp = {}\n",
    "    for tag in element.iter(\"tag\"):\n",
    "        temp['id'] = element.attrib[\"id\"]\n",
    "        if \":\" in tag.attrib[\"k\"]:\n",
    "            newKey = re.split(\":\",tag.attrib[\"k\"],1)\n",
    "            temp['key'] = newKey[1]\n",
    "            if temp['key'] == 'postcode':\n",
    "                temp['value'] = update_zipcode(tag.attrib[\"v\"])\n",
    "            elif temp['key'] == 'street':\n",
    "                temp['value'] = update_name(tag.attrib[\"v\"],mapping)\n",
    "            else:\n",
    "                temp['value'] = tag.attrib[\"v\"]\n",
    "            temp[\"type\"] = newKey[0]\n",
    "        else:\n",
    "            temp['key'] = tag.attrib[\"k\"]\n",
    "            if temp['key'] == 'postcode':\n",
    "                temp['value'] = update_zipcode(tag.attrib[\"v\"])\n",
    "            elif temp['key'] == 'street':\n",
    "                temp['value'] = update_name(tag.attrib[\"v\"],mapping)\n",
    "            else:\n",
    "                temp['value'] = tag.attrib[\"v\"]\n",
    "            temp[\"type\"] = default_tag_type\n",
    "        tags.append(temp.copy())  \n",
    "        \n",
    "    \n",
    "    if element.tag == 'node':\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_strings = (\n",
    "            \"{0}: {1}\".format(k, v if isinstance(v, str) else \", \".join(v))\n",
    "            for k, v in errors.iteritems()\n",
    "        )\n",
    "        raise cerberus.ValidationError(\n",
    "            message_string.format(field, \"\\n\".join(error_strings))\n",
    "        )\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "process_map(OSMFILE, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Analyze the data with SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Import CSV into SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "... and import those CSV files into an SQLite3 Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "db = sqlite3.connect(\"PerthWA.db\")\n",
    "c = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.execute('''DROP TABLE IF EXISTS nodes''')\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "c.execute('''\n",
    "CREATE TABLE nodes (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    lat REAL,\n",
    "    lon REAL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version INTEGER,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT\n",
    ");\n",
    "''')\n",
    "\n",
    "c.execute('''\n",
    "CREATE TABLE nodes_tags (\n",
    "    id INTEGER,\n",
    "    key TEXT,\n",
    "    value TEXT,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES nodes(id)\n",
    ");\n",
    "''')\n",
    "\n",
    "c.execute('''\n",
    "CREATE TABLE ways (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version TEXT,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT\n",
    ");\n",
    "''')\n",
    "\n",
    "c.execute('''\n",
    "CREATE TABLE ways_tags (\n",
    "    id INTEGER NOT NULL,\n",
    "    key TEXT NOT NULL,\n",
    "    value TEXT NOT NULL,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id)\n",
    ");\n",
    "''')\n",
    "\n",
    "c.execute('''\n",
    "CREATE TABLE ways_nodes (\n",
    "    id INTEGER NOT NULL,\n",
    "    node_id INTEGER NOT NULL,\n",
    "    position INTEGER NOT NULL,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id),\n",
    "    FOREIGN KEY (node_id) REFERENCES nodes(id)\n",
    ");\n",
    "''')\n",
    "\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the csv file as a dictionary, format the data as a list of tuples:\n",
    "with open('nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['lat'], i['lon'], i['user'].decode(\"utf-8\"), i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "    \n",
    "# insert the formatted data\n",
    "c.executemany(\"INSERT INTO nodes(id, lat, lon, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('nodes_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['key'], i['value'].decode(\"utf-8\"), i['type']) for i in dr]\n",
    "    \n",
    "# insert the formatted data\n",
    "c.executemany(\"INSERT INTO nodes_tags(id, key, value,type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('ways.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['user'].decode(\"utf-8\"), i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "    \n",
    "# insert the formatted data\n",
    "c.executemany(\"INSERT INTO ways(id, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('ways_nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['node_id'], i['position']) for i in dr]\n",
    "    \n",
    "# insert the formatted data\n",
    "c.executemany(\"INSERT INTO ways_nodes(id, node_id, position) VALUES (?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('ways_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['key'], i['value'].decode(\"utf-8\"), i['type']) for i in dr]\n",
    "    \n",
    "# insert the formatted data\n",
    "c.executemany(\"INSERT INTO ways_tags(id, key, value, type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Wrangling OSM.ipynb................: 74K  \n",
      "nodes.csv...............................: 19M  \n",
      "nodes_tags.csv..........................: 573K \n",
      "PerthWA.db..............................: 26M  \n",
      "perth_australia.osm.....................: 248M \n",
      "perth_australia_sample.osm..............: 50M  \n",
      "schema.py...............................: 2K   \n",
      "schema.pyc..............................: 1K   \n",
      "ways.csv................................: 1M   \n",
      "ways_nodes.csv..........................: 7M   \n",
      "ways_tags.csv...........................: 2M   \n",
      "Data Wrangling OSM-checkpoint.ipynb.....: 74K  \n"
     ]
    }
   ],
   "source": [
    "# Getting the list of files and their size\n",
    "dirpath = '.'\n",
    "\n",
    "files_list = []\n",
    "for path, dirs, files in os.walk(dirpath):\n",
    "    files_list.extend([(filename, size(os.path.getsize(os.path.join(path, filename)))) for filename in files])\n",
    "\n",
    "for filename, size in files_list:\n",
    "    print '{:.<40s}: {:5s}'.format(filename,size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29385"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of ways\n",
    "query = \"SELECT COUNT(*) FROM ways;\"\n",
    "c.execute(query)\n",
    "c.fetchall()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245081"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of nodes\n",
    "query = \"SELECT COUNT(*) FROM nodes;\"\n",
    "c.execute(query)\n",
    "c.fetchall()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 5 contributing users and their number of contributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'SDavies', 70607),\n",
       " (u'aaronsta', 34994),\n",
       " (u'browny_au', 27958),\n",
       " (u'sb9576', 21201),\n",
       " (u'Andrew Gregory', 11598)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 contributing users and their number of contributions\n",
    "query = \"SELECT e.user, COUNT(*) as num \\\n",
    "FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e GROUP BY e.user ORDER BY num DESC LIMIT 5;\"\n",
    "c.execute(query)\n",
    "c.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 most popular fast food chains and their count of restaurants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Hungry Jacks', 4),\n",
       " (u'Subway', 4),\n",
       " (u'Chicken Treat', 3),\n",
       " (u'Dominos', 3),\n",
       " (u'KFC', 3),\n",
       " (u\"McDonald's\", 3),\n",
       " (u'Chooks', 2),\n",
       " (u\"Domino's Pizza\", 2),\n",
       " (u\"Hungry Jack's\", 2),\n",
       " (u'Zambrero', 2)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 most popular fast food chains and their count of restaurants\n",
    "query = \"SELECT nodes_tags.value, COUNT(*) as num \\\n",
    "FROM nodes_tags JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='fast_food') as r \\\n",
    "    ON nodes_tags.id=r.id WHERE nodes_tags.key='name' \\\n",
    "GROUP BY nodes_tags.value ORDER BY num DESC LIMIT 10;\"\n",
    "c.execute(query)\n",
    "c.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 most represented types of amenities and their occurence count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'restaurant', 74),\n",
       " (u'fast_food', 73),\n",
       " (u'bench', 70),\n",
       " (u'cafe', 67),\n",
       " (u'drinking_water', 64),\n",
       " (u'post_box', 48),\n",
       " (u'parking', 42),\n",
       " (u'telephone', 36),\n",
       " (u'bicycle_parking', 32),\n",
       " (u'atm', 27),\n",
       " (u'toilets', 23),\n",
       " (u'fuel', 22),\n",
       " (u'pharmacy', 22),\n",
       " (u'pub', 22),\n",
       " (u'waste_basket', 20)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 most represented types of amenities and their occurence count\n",
    "query = \"SELECT value, COUNT(*) as num FROM nodes_tags WHERE key='amenity' \\\n",
    "GROUP BY value ORDER BY num DESC LIMIT 15;\"\n",
    "c.execute(query)\n",
    "c.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this project I selected and downloaded a metro extract of the geographical data related to the city of Perth, Australia. After sampling it to end up with a smaller OSM file, I audited it by looking at users, streetnames, and postcodes, and created functions to clean some of the errors linked to that sample file. Finally, I converted that OSM file into separate CSV files for nodes, tags and ways, and loaded those files into SQL to perform some exploratory queries over the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Overall I found the source data to be quite clean and standardized already, with only a few abbreviations used for street names and a couple of postcodes wrongly formatted. Nevertheless, it is still achievable to improve the auditing process of OpenStreetMap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Improvement ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Input Standardization: one of the first ideas would be to standardize the data from the input phase, by setting up rules to avoid wrong data entries. For instance, we saw in the postcode exercise that postcodes for Perth have 4 digits, and can either be written 'WA 0000' or simply '0000'. \n",
    "\n",
    "Benefit: Making a final decision about the format by automatically removing any letters from the postcodes inputs and flagging the ones that have more or less than 4 digits in a further audit will make sure the wrong inputs have a higher probability to get picked up in a later audit.\n",
    "\n",
    "Anticipated problem: Depending of the size of the area investigated, the list of anomalies could be quite time-consuming to audit, and it will be difficult to ensure that the result is coherent without a precise mapping of localities and postcodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Leveraging timestamps: Similarly, focusing on the timestamp associated with the inputs could improve the auditing process, should this audit be carried regularly and over a long enough timeline: the most recent entries can be audited more thorougly than the older ones which have already been cleaned.\n",
    "\n",
    "Benefit: if audits are performed regularly and thoroughly, focusing on the new additions can save time.\n",
    "\n",
    "Anticipated problem: if then correcting the mistakes in the recent inputs updates the timestamps, the corrected inputs will then appear again in the next review, adding an unecessary workload."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Users' contributions: Investigate further the users' contributions can also give us interesting insights into the data: from the \"Explore Users\" section, we ranked the top contributors to the Perth dataset and their count of submissions. What if we also kept track of the proportion of errors or anomalies flagged for all users? \n",
    "\n",
    "Benefit: We could then have a better understanding of which users submit the error-prone contributions, and what submissions should be looked into in priority.\n",
    "\n",
    "Anticipated problem: this analysis will have to be kept running on an ongoing basis, accounting for the additions and removals of users. This can prove to be difficult to set up or maintain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Third party tools (such as the Google Map API) could also be used to improve our exisiting data.\n",
    "\n",
    "Benefit: this will leverage existing data.\n",
    "\n",
    "Anticipated problem: this will be difficult to put into place at the beginning, as the two datasets could differ vastly. How do we review the different versions of the same node with accuracy and efficiency?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
